{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  #pacotes\n",
    "import numpy as np   #calculo numerico\n",
    "import glob          #listas\n",
    "import pyarrow.parquet as pq\n",
    "import os, sys\n",
    "from os import path\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para 30 dias\n",
    "\n",
    "list_ON  = [\n",
    "            '20250101','20250102','20250103','20250104','20250105','20250106','20250107',\n",
    "            '20250108','20250109','20250110','20250111','20250112','20250113','20250114',\n",
    "            '20250115','20250116','20250117','20250118','20250119','20250120','20250121',\n",
    "            '20250122','20250123','20250124','20250125','20250126','20250127','20250128',\n",
    "            '20250129','20250130'\n",
    "           ]\n",
    "\n",
    "list_OFF = [\n",
    "            '20241117','20241118','20241119','20241120','20241121','20241122','20241123',\n",
    "            '20241124','20241125','20241126','20241127','20241128','20241129','20241130',\n",
    "            '20241201','20241202','20241203','20241204','20241205','20241206','20241207',\n",
    "            '20241208','20241209','20241210','20241211','20241212','20241213','20241214',\n",
    "            '20241215','20241216'\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20241117', '20241118', '20241119', '20241120', '20241121', '20241122', '20241123', '20241124', '20241125', '20241126', '20241127', '20241128', '20241129', '2024113020241201', '20241202', '20241203', '20241204', '20241205', '20241206', '20241207', '20241208', '20241209', '20241210', '20241211', '20241212', '20241213', '20241214', '20241215', '20241216']\n"
     ]
    }
   ],
   "source": [
    "print (list_OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_interval = [63.134941, 66.91160302, 70.68826504, 74.46492707, 78.24158909,\n",
    " 82.01825112, 85.79491314, 89.57157517, 93.34823719, 97.12489922,\n",
    " 100.90156124, 104.67822326, 108.45488529, 112.23154731, 116.00820934, \n",
    " 119.78487136, 123.56153339, 127.33819541, 131.11485744, 134.89151946,\n",
    " 138.66818149, 142.44484351, 146.22150553, 149.99816756, 153.77482958,\n",
    " 157.55149161, 161.32815363, 165.10481566, 168.88147768, 172.65813971,\n",
    " 176.43480173, 180.21146375, 183.98812578, 187.7647878, 191.54144983,\n",
    " 195.31811185, 199.09477388, 202.8714359, 206.64809793, 210.42475995,\n",
    " 214.20142197, 217.978084, 221.75474602, 225.53140805, 229.30807007,\n",
    " 233.0847321, 236.86139412, 240.63805615, 244.41471817, 248.19138019]\n",
    "\n",
    "#print(bins_interval)\n",
    "\n",
    "def fnt_search_pos (f_pe):\n",
    "    arr = [i for i, j in enumerate(bins_interval) if j >= f_pe]\n",
    "    if len(arr)==0:\n",
    "        res=-1\n",
    "    else:\n",
    "        res = arr[0]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_epoch(filename):\n",
    "  initial = str(filename).find('AngraRun') + 6\n",
    "  final = str(filename).find('AngraRun') + 24\n",
    "  sub = str(filename)[initial:final]\n",
    "  epoch = ''.join(i for i in sub if i.isdigit())\n",
    "  #print(epoch)\n",
    "  return(epoch)\n",
    "\n",
    "def find_interval_date_pair(datein, datefi, sdir):  #enviar formato yyyy-mm-dd\n",
    "    \n",
    "    ts_datein = int(datetime.datetime(int(datein[0:4]),int(datein[5:7]),int(datein[8:10]),0,0).timestamp())\n",
    "    ts_datefi = int(datetime.datetime(int(datefi[0:4]),int(datefi[5:7]),int(datefi[8:10]),23,59).timestamp())\n",
    "    \n",
    "    fileparq  = sdir+'/*.parq'  #nova pasta dos processados - 05/04/2021\n",
    "    listparq = glob.glob(fileparq)\n",
    "    interval_list = []\n",
    "    i_fator = 1000  #novo v4 divide por 1000 - 05/04/2021\n",
    "    \n",
    "    for file in listparq:\n",
    "        #print(file)\n",
    "        i_filedate = int(extract_epoch(file))/i_fator  # somente se não for v2 divide por 1000 (por que?)\n",
    "        day_filedate = datetime.datetime.fromtimestamp(i_filedate).day\n",
    "        month_filedate = datetime.datetime.fromtimestamp(i_filedate).month\n",
    "        year_filedate = datetime.datetime.fromtimestamp(i_filedate).year\n",
    "        ts_filedate = int(datetime.datetime(year_filedate,month_filedate,day_filedate,0,0).timestamp())\n",
    "        #print('{:s} >> data/hora run: {:d}-{:d}-{:d}'.format(file,year_filedate,month_filedate,day_filedate))\n",
    "        if ts_filedate >= ts_datein and ts_filedate <= ts_datefi: \n",
    "            interval_list.append(file)\n",
    "        \n",
    "    return(interval_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnt_process_list_PD (p_list, p_h_PDP, p_h_PDD, p_h_PDT, p_list_bins):\n",
    "    i_day = 0\n",
    "    p_totalPositrons = 0\n",
    "    p_totalNonSat = 0\n",
    "    p_count_bin = [ [] for y in range(len(p_list)) ]\n",
    "    p_dp_bin = [ [] for y in range(len(p_list)) ]\n",
    "    p_dpr_bin = [ [] for y in range(len(p_list)) ]                      \n",
    "\n",
    "    for sListDt in p_list:\n",
    "        yyyy=int(sListDt[0:4]); mm=int(sListDt[4:6]); dd=int(sListDt[6:8])\n",
    "    \n",
    "        sDate = '{0:d}-{1:0>2d}-{2:0>2d}'.format(yyyy,mm,dd)\n",
    "        sDir='pair/{0:d}{1:0>2d}{2:0>2d}'.format(yyyy,mm,dd)\n",
    "        print(sDir)\n",
    "        lista = find_interval_date_pair(sDate,sDate,sDir)\n",
    "        p_h_NonSat = []\n",
    "\n",
    "        for file in lista:\n",
    "            print(' >>> '+file)\n",
    "            df = pd.read_parquet(file)\n",
    "            dff = df[(df['p_satured']==0)&(df['d_satured']==0)\n",
    "                            &(fnt_pe2MeV(df['p_Total_pe'])>=3)&(fnt_pe2MeV(df['p_Total_pe'])<=10)\n",
    "                            &(fnt_pe2MeV(df['d_Total_pe'])>=1.6)&(fnt_pe2MeV(df['d_Total_pe'])<=7.12)\n",
    "                            &(df['d_timeInverval']>=8)&(df['d_timeInverval']<=50)\n",
    "                            &(df['d_mPMTs']>=25)\n",
    "                    ]\n",
    "            p_h_PDP.extend(dff['p_Total_pe'].values)\n",
    "            p_h_PDD.extend(dff['d_Total_pe'].values)\n",
    "            p_h_PDT.extend(dff['d_timeInverval'].values)\n",
    "\n",
    "            dfns = df[(df['p_satured']==0)&(df['d_satured']==0)]\n",
    "\n",
    "            p_totalPositrons += df.count()[0]\n",
    "            p_totalNonSat += dfns.count()[0]\n",
    "\n",
    "            p_h_NonSat.extend(dff['p_Total_pe'].values)            \n",
    "\n",
    "            #print(p_totalPositrons)\n",
    "            #break\n",
    "                \n",
    "        print('calculando bin')\n",
    "                      \n",
    "        p_bin_NonSat = [ [] for y in range(len(p_list_bins)) ]\n",
    "                      \n",
    "        ## 1- Navegar na lista de prompt dos eventos filtrados e separá-los em bins de pe\n",
    "        for iw in range(len(p_h_NonSat)):\n",
    "            i_b_pos = fnt_search_pos(p_h_NonSat[iw])\n",
    "            if (i_b_pos!=-1):\n",
    "                p_bin_NonSat[i_b_pos].append(p_h_NonSat[iw])\n",
    "        \n",
    "        ## 2- Navegar na lista de bins e contar quantos eventos ocorreram no dia\n",
    "        for sb in range(len(p_list_bins)):\n",
    "            p_count_bin[i_day].append(len(p_bin_NonSat[sb]))\n",
    "\n",
    "        i_day += 1\n",
    "        #break   ## Somente 1 dia de runs\n",
    "\n",
    "    print('calculando sigmas')\n",
    "    p_sigma_bin = []\n",
    "    for sbr in range(len(p_list_bins)):\n",
    "        cday_NSat = []\n",
    "        for dd in range(i_day):\n",
    "            cday_NSat.append(p_count_bin[dd][sbr])\n",
    "         \n",
    "        p_sigma_bin.append(np.sum(cday_NSat))  # contagem de eventos/dia\n",
    "\n",
    "    return p_totalPositrons, p_totalNonSat, p_sigma_bin #, p_sigmar_bin, p_std_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save values - h_Sig_OFF2 (contém o sigma de cada bin dividido por 5dias)\n",
    "def save_PD (dh_PDP, dh_PDD, dh_PDT, dh_Sig, sName):\n",
    "    # dictionary of lists\n",
    "    dict = {'dh_PDP': dh_PDP,\n",
    "            'dh_PDD': dh_PDD,\n",
    "            'dh_PDT': dh_PDT}\n",
    "    \n",
    "    dict2 = {'dh_Sig': dh_Sig}\n",
    " \n",
    "    # creating a dataframe from dictionary\n",
    "    dfw = pd.DataFrame(dict)\n",
    "    dfw.to_parquet('pair/Analise_ONOFF/'+sName+'.parq', compression='gzip')\n",
    "\n",
    "    dfw2 = pd.DataFrame(dict2)\n",
    "    dfw2.to_parquet('pair/Analise_ONOFF/Sig_'+sName+'.parq', compression='gzip')\n",
    "\n",
    "    del dict2\n",
    "    del dict\n",
    "    \n",
    "##load values\n",
    "def load_PD (sName): #(dh_PDP, dh_PDD, dh_PDT, dh_Sig, sName):\n",
    "    dfr = pd.read_parquet('pair/Analise_ONOFF/'+sName+'.parq')\n",
    "    dfr2 = pd.read_parquet('pair/Analise_ONOFF/Sig_'+sName+'.parq')\n",
    "    return(dfr['dh_PDP'].values, dfr['dh_PDD'].values, dfr['dh_PDT'].values, dfr2['dh_Sig'].values)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio 2025-05-28 11:05:18.791289\n",
      "pair/20241117\n",
      "calculando bin\n",
      "pair/20241118\n",
      "calculando bin\n",
      "pair/20241119\n",
      "calculando bin\n",
      "pair/20241120\n",
      "calculando bin\n",
      "pair/20241121\n",
      "calculando bin\n",
      "pair/20241122\n",
      "calculando bin\n",
      "pair/20241123\n",
      "calculando bin\n",
      "pair/20241124\n",
      "calculando bin\n",
      "pair/20241125\n",
      "calculando bin\n",
      "pair/20241126\n",
      "calculando bin\n",
      "pair/20241127\n",
      "calculando bin\n",
      "pair/20241128\n",
      "calculando bin\n",
      "pair/20241129\n",
      "calculando bin\n",
      "pair/20241130\n",
      "calculando bin\n",
      "pair/20241202\n",
      "calculando bin\n",
      "pair/20241203\n",
      "calculando bin\n",
      "pair/20241204\n",
      "calculando bin\n",
      "pair/20241205\n",
      "calculando bin\n",
      "pair/20241206\n",
      "calculando bin\n",
      "pair/20241207\n",
      "calculando bin\n",
      "pair/20241208\n",
      "calculando bin\n",
      "pair/20241209\n",
      "calculando bin\n",
      "pair/20241210\n",
      "calculando bin\n",
      "pair/20241211\n",
      "calculando bin\n",
      "pair/20241212\n",
      "calculando bin\n",
      "pair/20241213\n",
      "calculando bin\n",
      "pair/20241214\n",
      "calculando bin\n",
      "pair/20241215\n",
      "calculando bin\n",
      "pair/20241216\n",
      "calculando bin\n",
      "calculando sigmas\n",
      "0\n",
      "0\n",
      "0\n",
      "Em  29  dias:  0\n",
      "Por dia:  0.0\n",
      "Em Hz:  0.0\n",
      "Em  29  dias (NS):  0\n",
      "Por dia (NS):  0.0\n",
      "Em Hz (NS):  0.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Fim 2025-05-28 11:05:18.931916\n"
     ]
    }
   ],
   "source": [
    "print('Inicio',datetime.datetime.now())\n",
    "h_PDP_OFF = []\n",
    "h_PDD_OFF = []\n",
    "h_PDT_OFF = []\n",
    "h_Sig_OFF = []\n",
    "\n",
    "totalPositrons_OFF = 0\n",
    "totalNonSat_OFF = 0\n",
    "\n",
    "totalPositrons_OFF, totalNonSat_OFF, h_Sig_OFF = fnt_process_list_PD(list_OFF, h_PDP_OFF, h_PDD_OFF, h_PDT_OFF, bins_interval)\n",
    "                            \n",
    "print(len(h_PDP_OFF))\n",
    "print(len(h_PDD_OFF))\n",
    "print(len(h_PDT_OFF))\n",
    "print('Em ',len(list_OFF),' dias: ',totalPositrons_OFF)\n",
    "print('Por dia: ',totalPositrons_OFF/len(list_OFF))\n",
    "print('Em Hz: ',totalPositrons_OFF/len(list_OFF)/86400) \n",
    "print('Em ',len(list_OFF),' dias (NS): ',totalNonSat_OFF)\n",
    "print('Por dia (NS): ',totalNonSat_OFF/len(list_OFF))\n",
    "print('Em Hz (NS): ',totalNonSat_OFF/len(list_OFF)/86400) \n",
    "\n",
    "print(h_Sig_OFF)\n",
    "print(np.sum(h_Sig_OFF))\n",
    "\n",
    "hg_Sig_OFF = [(x**0.5) for x in h_Sig_OFF]\n",
    "print(hg_Sig_OFF)\n",
    "\n",
    "        \n",
    "print('Fim',datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Inicio',datetime.datetime.now())\n",
    "\n",
    "h_PDP_ON = []\n",
    "h_PDD_ON = []\n",
    "h_PDT_ON = []\n",
    "h_Sig_ON = []\n",
    "\n",
    "totalPositrons_ON = 0\n",
    "totalNonSat_ON = 0\n",
    "\n",
    "totalPositrons_ON, totalNonSat_ON, h_Sig_ON = fnt_process_list_PD(list_ON, h_PDP_ON, h_PDD_ON, h_PDT_ON, bins_interval)\n",
    "\n",
    "print(len(h_PDP_ON))\n",
    "print(len(h_PDD_ON))\n",
    "print(len(h_PDT_ON))\n",
    "print('Em ',len(list_ON),' dias: ',totalPositrons_ON)\n",
    "print('Por dia: ',totalPositrons_ON/len(list_ON))\n",
    "print('Em Hz: ',totalPositrons_ON/len(list_ON)/86400) \n",
    "print('Em ',len(list_ON),' dias (NS): ',totalNonSat_ON)\n",
    "print('Por dia (NS): ',totalNonSat_ON/len(list_ON))\n",
    "print('Em Hz (NS): ',totalNonSat_ON/len(list_ON)/86400) \n",
    "\n",
    "hg_Sig_ON = [(x**0.5) for x in h_Sig_ON]\n",
    "print(hg_Sig_ON)\n",
    "\n",
    "print('Fim',datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_day = 30\n",
    "\n",
    "hg_Sig_ON = [((x*i_day)**0.5) for x in h_Sig_ON]     ## x é a quantidade do bin / quantidade de dias \n",
    "hg_Sig_OFF = [((x*i_day)**0.5) for x in h_Sig_OFF] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_PD (h_PDP_ON, h_PDD_ON, h_PDT_ON, hg_Sig_ON, 'PD_ON_30')\n",
    "save_PD (h_PDP_OFF, h_PDD_OFF, h_PDT_OFF, hg_Sig_OFF, 'PD_OFF_30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_PDP_ON, h_PDD_ON, h_PDT_ON, hg_Sig_ON = load_PD ( 'PD_ON_30')\n",
    "h_PDP_OFF, h_PDD_OFF, h_PDT_OFF, hg_Sig_OFF = load_PD ( 'PD_OFF_30')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
